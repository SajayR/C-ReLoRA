experiment:
  name: vit-base-lora-4
  name_suffix: rank-4
  seed: 42
  device: auto
  output_dir: ./runs

model:
  name: vit_base_lora
  params:
    model_name: google/vit-base-patch16-224
    dropout: 0.1
    freeze_backbone: false
    gradient_checkpointing: false
    lora:
      enabled: true
      r: 4
      alpha: 8
      dropout: 0.0
      target_modules:
        ["query", "key", "value", "output.dense", "intermediate.dense"]

training:
  epochs: 5
  gradient_clip_norm: 1.0
  grad_accumulation: 1
  log_every: 1
  eval_every: 1
  save_every: 1
  precision:
    enabled: true
    dtype: bf16
    grad_scaler: false
  optimizer:
    type: adamw
    lr: 0.0003
    weight_decay: 0.05
    betas: [0.9, 0.999]
    eps: 0.00000001
  scheduler:
    type: cosine
    warmup: 0.1
    min_lr_mult: 0.1
  monitor:
    grad_norm: true
    param_norm: true
    memory: true

data:
  root: /speedy/datasets
  image_size: 224
  batch_size: 128
  num_workers: 8
  pin_memory: true
  persistent_workers: true
  normalization: vit
  augment: true
  drop_last: true

logging:
  use_wandb: true
  project: cis-testbed
  entity: null
  run_name: null
  group: null
  tags: ["vit", "lora", "4"]
  notes: null

datasets:
  - name: cifar-100
    val_split: test
    normalization: vit
  - name: cifar-10
    val_split: test
    normalization: vit
